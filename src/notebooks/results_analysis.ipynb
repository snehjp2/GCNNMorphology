{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "from torch import tensor\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsAnalysis:\n",
    "    \n",
    "    def __init__(self, yaml_path, noise_level: int = 0):\n",
    "        \n",
    "        self.class_names = ('Disturbed Galaxies', 'Merging Galaxies', \n",
    "        'Round Smooth Galaxies', 'In-between Round Smooth Galaxies', \n",
    "        'Cigar Shaped Smooth Galaxies', 'Barred Spiral Galaxies', \n",
    "        'Unbarred Tight Spiral Galaxies', 'Unbarred Loose Spiral Galaxies', \n",
    "        'Edge-on Galaxies without Bulge', 'Edge-on Galaxies with Bulge')\n",
    "    \n",
    "        self.noise_level = noise_level\n",
    "        with open(yaml_path, \"r\") as f:\n",
    "            data = yaml.safe_load(f)\n",
    "            \n",
    "        models = []\n",
    "        accuracies = []\n",
    "        for model_name, model_data in data.items():\n",
    "            # Create a dictionary to store the data for each class\n",
    "            class_data = {}\n",
    "\n",
    "            for class_name, class_metrics in model_data.items():\n",
    "                    # Add the metrics for the class to the dictionary\n",
    "                    if isinstance(class_metrics, dict):\n",
    "                        class_data[class_name] = {\n",
    "                            \"f1-score\": class_metrics[\"f1-score\"],\n",
    "                            \"precision\": class_metrics[\"precision\"],\n",
    "                            \"recall\": class_metrics[\"recall\"],\n",
    "                            \"support\": class_metrics[\"support\"]\n",
    "                        }\n",
    "                    else:\n",
    "                        accuracies.append(class_metrics)\n",
    "                        \n",
    "            models.append({\n",
    "                \"Model\": model_name,\n",
    "                **{f\"{class_name.lower()} - {metric_name}\": class_metrics[metric_name] for class_name, class_metrics in class_data.items() for metric_name in class_metrics}\n",
    "            })\n",
    "\n",
    "        # Create a pandas dataframe from the list of dictionaries\n",
    "        self.df = pd.DataFrame(models)\n",
    "        self.df['Accuracy'] = accuracies\n",
    "        \n",
    "    def plot_heatmap(self):\n",
    "        self.df_filtered = self.df[self.df.index != \"Accuracy\"].drop(columns=['Accuracy'])\n",
    "        self.df_filtered = self.df_filtered.set_index(\"Model\")\n",
    "        self.df_filtered = self.df_filtered.drop(columns=[col for col in self.df_filtered.columns if 'support' in col])\n",
    "        self.df_filtered = self.df_filtered.drop(columns=[col for col in self.df_filtered.columns if 'precision' in col])\n",
    "        self.df_filtered = self.df_filtered.drop(columns=[col for col in self.df_filtered.columns if 'recall' in col])\n",
    "        # Transpose the dataframe so that models are on the x-axis and classes are on the y-axis\n",
    "        self.df_transposed = self.df_filtered.transpose()\n",
    "        \n",
    "        # Set the size of the plot\n",
    "        plt.figure(figsize=(8, 4))\n",
    "\n",
    "        # Create the heatmap\n",
    "        sns.heatmap(self.df_transposed, annot=False, cmap=\"Blues\")\n",
    "\n",
    "        # Set the title and axis labels\n",
    "        plt.title(f\"F1 Scores (Noise Level: {self.noise_level}%)\")\n",
    "        plt.xlabel(\"Model\")\n",
    "        plt.ylabel(\"F1-Score\")\n",
    "\n",
    "        # Rotate the x-axis labels for better readability\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "        # Show the plot\n",
    "        # plt.show()\n",
    "        \n",
    "    def plot_accuracy(self, ax=None):\n",
    "        model_names = self.df[\"Model\"].tolist()\n",
    "        accuracies = self.df['Accuracy'].tolist()\n",
    "\n",
    "        # Sort the model names and accuracy values in descending order of accuracy\n",
    "        model_names, accuracies = zip(*sorted(zip(model_names, accuracies), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "        # Set the size of the plot\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        # Create a horizontal bar chart showing the accuracy for each model\n",
    "        bars = ax.barh(model_names, accuracies)\n",
    "\n",
    "        # Set the color of the bars to indicate the accuracy, with red for the worst performing model and green for the best performing model\n",
    "        for i, bar in enumerate(bars):\n",
    "            if i == 0:\n",
    "                bar.set_color(\"g\")\n",
    "            elif i == len(bars) - 1:\n",
    "                bar.set_color(\"r\")\n",
    "            else:\n",
    "                bar.set_color(\"gray\")\n",
    "\n",
    "        # Add labels and a title to the chart\n",
    "        ax.set_xlabel(\"Accuracy\")\n",
    "        ax.set_title(f\"Model Accuracies (Noise Level: {self.noise_level}%)\")\n",
    "\n",
    "    def plot_precision_recall(self, class_name: str):\n",
    "        class_name = class_name.lower()\n",
    "        models = self.df['Model'].unique()\n",
    "        models_list = ', '.join(models).split(', ')\n",
    "        colors = plt.cm.tab20(np.arange(20))\n",
    "\n",
    "        additional_colors = np.random.rand(5, 3)\n",
    "        if additional_colors.shape[1] < colors.shape[1]:\n",
    "            additional_colors = np.hstack([additional_colors, np.ones((5, colors.shape[1] - additional_colors.shape[1]))])\n",
    "        colors = np.vstack([colors, additional_colors])\n",
    "\n",
    "        precision_col = [col for col in self.df.columns if 'precision' in col.lower() and class_name in col.lower()][0]\n",
    "        recall_col = [col for col in self.df.columns if 'recall' in col.lower() and class_name in col.lower()][0]\n",
    "\n",
    "        for i, model_name in enumerate(models_list):\n",
    "            model_data = self.df[self.df['Model'] == model_name]\n",
    "            plt.scatter(model_data[recall_col], model_data[precision_col], label=model_name, color=colors[i])\n",
    "\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title(f'{class_name.title()} Precision-Recall Scatter Plot (Noise Level: {self.noise_level}%)')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1.05))\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = ResultsAnalysis(\"/Users/snehpandya/Projects/GCNNMorphology/data/test_metrics.yaml\", 0)\n",
    "tm25 = ResultsAnalysis(\"/Users/snehpandya/Projects/GCNNMorphology/data/test_metrics_25.yaml\", 75)\n",
    "tm50 = ResultsAnalysis(\"/Users/snehpandya/Projects/GCNNMorphology/data/test_metrics_50.yaml\", 50)\n",
    "tm75 = ResultsAnalysis(\"/Users/snehpandya/Projects/GCNNMorphology/data/test_metrics_75.yaml\", 25)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
